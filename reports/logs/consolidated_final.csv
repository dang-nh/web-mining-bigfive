Model,Language,RMSE,MAE,Accuracy,Pearson
TF-IDF Baseline,en,0.1399123322562113,0.1123699300082355,0.4983050847457628,0.6741883826895407
Twitter-RoBERTa (Chunked),en,0.1159371928234322,0.0845311978929755,0.6847457627118644,0.7212940428807302
XLM-RoBERTa (Chunked),en,0.1306666882524887,0.0984735581285115,0.6169491525423729,0.6281657501891436
TF-IDF Baseline,es,0.1510441056143519,0.1221629320797556,0.4894736842105264,0.6772594868582752
XLM-RoBERTa (Chunked),es,0.1410030902980792,0.1110887476542082,0.5421052631578948,0.6793170247654143
XLM-RoBERTa (Chunked),es_twitter,0.1312779018005917,0.1048915221895042,0.5842105263157895,0.7523503654868302
TF-IDF Baseline,it,0.1201480419839587,0.1027252160385968,0.5733333333333334,0.6662124854868718
XLM-RoBERTa (Chunked),it,0.1375846202129314,0.1190183147961894,0.4933333333333333,0.6636260522382569
XLM-RoBERTa (Chunked),it_twitter,0.109592876532792,0.0874682456503311,0.6133333333333333,0.7014923647319129
TF-IDF Baseline,nl,0.1249488854642898,0.1029148100318274,0.6285714285714286,0.8043130241408427
XLM-RoBERTa (Chunked),nl,0.1559365515027536,0.132453214845487,0.4142857142857142,0.6058888848918207
XLM-RoBERTa (Chunked),nl_twitter,0.1002233775932732,0.0822234323913497,0.6714285714285714,0.8889402835424873
